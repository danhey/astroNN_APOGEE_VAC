{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d16e5bb-940d-4950-91a8-dba516a1307c",
   "metadata": {},
   "source": [
    "# Training script for astroNN VAC DR17\n",
    "\n",
    "This notebook contains training script for astroNN VAC DR17 models (i.e. stellar parameters, distances and ages)\n",
    "\n",
    "Please notics that all the required files can be generated by the scripts provided in the upper level, so you have to move the files to this directory or move the notebooks from this directory to upper level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62fdc71-70d2-4213-92c2-50fe244786d1",
   "metadata": {},
   "source": [
    "## Chemical abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42e39e-9262-4af5-af84-c8cf7f5cdb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from astropy.io import fits\n",
    "\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored, ApogeeBCNN\n",
    "from astroNN.apogee import allstar\n",
    "from astroNN.datasets import xmatch\n",
    "from astroNN.nn.losses import mean_absolute_error, mean_error, mean_absolute_percentage_error\n",
    "\n",
    "f = fits.getdata(allstar(dr=17))\n",
    "f16 = fits.getdata(allstar(dr=16))\n",
    "\n",
    "contspec_mask = fits.open(\"contspec_dr17_synspec.fits\")[1].data\n",
    "contspec = fits.getdata(\"contspec_dr17_synspec.fits\")\n",
    "\n",
    "# loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "#                  'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "\n",
    "vscatter = f['VSCATTER']\n",
    "SNR = f['SNR']\n",
    "location_id = f['LOCATION_ID']\n",
    "teff = f['PARAM'][:, 0]\n",
    "fe = f['X_H'][:, 17]\n",
    "\n",
    "starflag = f['STARFLAG']\n",
    "aspcapflag = f['ASPCAPFLAG']\n",
    "\n",
    "good_idx = (np.array(contspec_mask, bool) & (starflag==0) & (aspcapflag==0) & (vscatter<1) & \n",
    "            (SNR>200) & (f['TEFF']>3000) & (f['TEFF']<6500) & (np.invert(np.isnan(fe))) & \n",
    "            (np.invert(np.isnan(f['X_H'][:, 5]))))\n",
    "\n",
    "ra = f[\"RA\"][good_idx]\n",
    "dec = f[\"DEC\"][good_idx]\n",
    "\n",
    "idx1, idx2, sep = xmatch(ra, dec, f16[\"RA\"], f16[\"DEC\"])\n",
    "\n",
    "labels = np.array(np.hstack([np.stack([f[\"TEFF\"], f['LOGG']]).T, f[\"X_H\"][:, :20]])[good_idx], dtype=np.float64)\n",
    "labels_err = np.array(np.hstack([np.stack([f[\"TEFF_ERR\"], f['LOGG_ERR']]).T, f[\"X_H_ERR\"][:, :20]])[good_idx], dtype=np.float64)\n",
    "input_spec = contspec[good_idx]\n",
    "\n",
    "bad_aspcap_params = (f[\"ELEMFLAG\"][:, :20][good_idx] != 0)\n",
    "labels[:, 2:][bad_aspcap_params] = -9999.\n",
    "labels_err[:, 2:][bad_aspcap_params] = -9999.\n",
    "\n",
    "# inject P_H\n",
    "labels[idx1, 10] = f16[\"X_H\"][:, 8][idx2]\n",
    "labels_err[idx1, 10] = f16[\"X_H_ERR\"][:, 8][idx2]\n",
    "\n",
    "# setup astroNN mdoel instance\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.batch_size = 256\n",
    "bcnn.input_norm_mode = 3  # center label but not scale pixel\n",
    "bcnn.metrics = [mean_absolute_error, mean_error, mean_absolute_percentage_error]\n",
    "bcnn.num_hidden = [256, 96, 32, 16, 2]\n",
    "bcnn.max_epochs = 60\n",
    "bcnn.reduce_lr_patience = 5\n",
    "bcnn.autosave=True\n",
    "# train\n",
    "bcnn.fit(input_spec, labels, labels_err=labels_err)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d2d1a-5188-4aae-957f-42f927ca0e33",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3535ed94-f115-411e-b4a0-624bcbd0e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "from astroNN.apogee import allstar\n",
    "from astroNN.gaia import mag_to_fakemag, extinction_correction, fakemag_to_logsol\n",
    "\n",
    "\n",
    "file = fits.open(\"contspec_dr17_synspec.fits\")\n",
    "allstar_file = fits.getdata(allstar(dr=17))\n",
    "gaia_data_file = fits.getdata(\"apogeedr17_syncspec_gaiaedr3_xmatch.fits\")\n",
    "all_spec = file[0].data\n",
    "good_flag = file[1].data\n",
    "\n",
    "###### Zero-point correction from Gaia ######\n",
    "from zero_point import zpt\n",
    "\n",
    "zpt.load_tables()\n",
    "\n",
    "good_idx = np.where(((gaia_data_file[\"astrometric_params_solved\"]==31) | (gaia_data_file[\"astrometric_params_solved\"]==95)) & \n",
    "                    (gaia_data_file[\"phot_g_mean_mag\"]<21) & (6<gaia_data_file[\"phot_g_mean_mag\"]))[0]\n",
    "\n",
    "zp = zpt.get_zpt(gaia_data_file[\"phot_g_mean_mag\"][good_idx], \n",
    "                 gaia_data_file[\"nu_eff_used_in_astrometry\"][good_idx], \n",
    "                 gaia_data_file[\"pseudocolour\"][good_idx], \n",
    "                 gaia_data_file[\"ecl_lat\"][good_idx], \n",
    "                 gaia_data_file[\"astrometric_params_solved\"][good_idx])\n",
    "\n",
    "# use median zero-point for all stars by default\n",
    "zp_row_matched = np.ones(len(allstar_file)) * np.median(zp)\n",
    "\n",
    "zp_row_matched[good_idx] = zp\n",
    "###### Zero-point correction from Gaia ######\n",
    "\n",
    "extinction = allstar_file['AK_TARG']\n",
    "extinction[(extinction < 0.) & np.isnan(extinction)] = -9999  # assume corrupted extinction if negative extinction\n",
    "ra = gaia_data_file['RA']\n",
    "dec = gaia_data_file['DEC']\n",
    "parallax = gaia_data_file['parallax']\n",
    "parallax_w_zp = gaia_data_file['parallax'] - zp_row_matched\n",
    "parallax_error = gaia_data_file['parallax_error']\n",
    "\n",
    "# if extinction_method is IRAC then flag it as good, otherwise not good\n",
    "extinction_method = np.zeros_like(ra)\n",
    "extinction_method[allstar_file['AK_TARG_METHOD'] == 'RJCE_IRAC'] = 1\n",
    "\n",
    "corrected_K = extinction_correction(allstar_file['K'], extinction)\n",
    "fakemag, fakemag_error = mag_to_fakemag(corrected_K, parallax, parallax_error)\n",
    "fakemag_w_zp, fakemag_w_zp_error = mag_to_fakemag(corrected_K, parallax_w_zp, parallax_error)\n",
    "logsol = fakemag_to_logsol(fakemag)\n",
    "logsol_w_zp = fakemag_to_logsol(fakemag_w_zp)\n",
    "\n",
    "# cutting criteria for training set\n",
    "good_idx = ((~np.isnan(parallax)) & (parallax_error < 0.1) & (parallax < 1e10) & (allstar_file['SNR'] > 200) &\n",
    "            (~np.isnan(allstar_file['K'])) & (allstar_file['K']<90) & (gaia_data_file['ruwe'] < 1.4) & (fakemag != -9999.) & \n",
    "            (good_flag==1) & (allstar_file['vscatter'] < 1.) & (allstar_file['STARFLAG'] == 0) & ((logsol > 0) | (parallax < 0)) & \n",
    "            (gaia_data_file['ipd_frac_multi_peak'] <= 2) & (gaia_data_file['ipd_gof_harmonic_amplitude'] < 0.1))\n",
    "\n",
    "# cutting criteria for testing set\n",
    "good_test_idx = ((~np.isnan(parallax)) & (parallax_error < 0.1) & (parallax < 1e10) & (allstar_file['SNR'] < 200) & \n",
    "                 (~np.isnan(allstar_file['K'])) & (allstar_file['K']<90) & (gaia_data_file['ruwe'] < 1.4) & (fakemag != -9999.) &\n",
    "                 (good_flag==1) & (allstar_file['vscatter'] < 1.) & (allstar_file['STARFLAG'] == 0) & ((logsol > 0) | (parallax < 0)) & \n",
    "                 (gaia_data_file['ipd_frac_multi_peak'] <= 2) & (gaia_data_file['ipd_gof_harmonic_amplitude'] < 0.1))\n",
    "\n",
    "print(\"Training Set Spectra: \", np.sum(good_idx))\n",
    "print(\"Low SNR Combined Spectra Testing Set Spectra: \", np.sum(good_test_idx))\n",
    "\n",
    "h5f = h5py.File('gaia_edr3_dr17_syncspec_train.h5', 'w')\n",
    "h5f.create_dataset('spectra', data=all_spec[good_idx])\n",
    "h5f.create_dataset('RA', data=allstar_file['RA'][good_idx])\n",
    "h5f.create_dataset('DEC', data=allstar_file['DEC'][good_idx])\n",
    "h5f.create_dataset('SNR', data=allstar_file['SNR'][good_idx])\n",
    "h5f.create_dataset('allstar_idx', data=np.arange(allstar_file['RA'].shape[0])[good_idx])\n",
    "h5f.create_dataset('ASPCAP_TEFF', data=allstar_file['TEFF'][good_idx])\n",
    "h5f.create_dataset('ASPCAP_LOGG', data=allstar_file['LOGG'][good_idx])\n",
    "h5f.create_dataset('fakemag', data=fakemag[good_idx])\n",
    "h5f.create_dataset('fakemag_err', data=fakemag_error[good_idx])\n",
    "h5f.create_dataset('fakemag_w_zp', data=fakemag_w_zp[good_idx])\n",
    "h5f.create_dataset('fakemag_w_zp_err', data=fakemag_w_zp_error[good_idx])\n",
    "h5f.create_dataset('corrected_K', data=corrected_K[good_idx])  # extinction corrected\n",
    "h5f.create_dataset('extinction', data=extinction[good_idx])\n",
    "h5f.create_dataset('extinction_method', data=extinction_method[good_idx])\n",
    "h5f.create_dataset('parallax', data=parallax[good_idx])\n",
    "h5f.create_dataset('parallax_err', data=parallax_error[good_idx])\n",
    "h5f.create_dataset('parallax_w_zp', data=parallax_w_zp[good_idx])\n",
    "h5f.create_dataset('bp_rp', data=gaia_data_file['bp_rp'][good_idx])\n",
    "h5f.create_dataset('phot_g_mean_mag', data=gaia_data_file['phot_g_mean_mag'][good_idx])\n",
    "h5f.close()\n",
    "\n",
    "h5f = h5py.File('gaia_edr3_dr17_syncspec_test.h5', 'w')\n",
    "h5f.create_dataset('spectra', data=all_spec[good_test_idx])\n",
    "h5f.create_dataset('RA', data=allstar_file['RA'][good_test_idx])\n",
    "h5f.create_dataset('DEC', data=allstar_file['DEC'][good_test_idx])\n",
    "h5f.create_dataset('SNR', data=allstar_file['SNR'][good_test_idx])\n",
    "h5f.create_dataset('allstar_idx', data=np.arange(allstar_file['RA'].shape[0])[good_test_idx])\n",
    "h5f.create_dataset('ASPCAP_TEFF', data=allstar_file['TEFF'][good_test_idx])\n",
    "h5f.create_dataset('ASPCAP_LOGG', data=allstar_file['LOGG'][good_test_idx])\n",
    "h5f.create_dataset('fakemag', data=fakemag[good_test_idx])\n",
    "h5f.create_dataset('fakemag_err', data=fakemag_error[good_test_idx])\n",
    "h5f.create_dataset('fakemag_w_zp', data=fakemag_w_zp[good_test_idx])\n",
    "h5f.create_dataset('fakemag_w_zp_err', data=fakemag_w_zp_error[good_test_idx])\n",
    "h5f.create_dataset('corrected_K', data=corrected_K[good_test_idx])  # extinction corrected\n",
    "h5f.create_dataset('extinction', data=extinction[good_test_idx])\n",
    "h5f.create_dataset('extinction_method', data=extinction_method[good_test_idx])\n",
    "h5f.create_dataset('parallax', data=parallax[good_test_idx])\n",
    "h5f.create_dataset('parallax_err', data=parallax_error[good_test_idx])\n",
    "h5f.create_dataset('parallax_w_zp', data=parallax_w_zp[good_test_idx])\n",
    "h5f.create_dataset('bp_rp', data=gaia_data_file['bp_rp'][good_test_idx])\n",
    "h5f.create_dataset('phot_g_mean_mag', data=gaia_data_file['phot_g_mean_mag'][good_test_idx])\n",
    "h5f.close()\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import tensorflow as tf \n",
    "\n",
    "from astroNN.nn.losses import mean_absolute_error, mean_error, mean_absolute_percentage_error\n",
    "from astroNN.models import ApogeeBCNN\n",
    "from astroNN.nn.callbacks import ErrorOnNaN\n",
    "from astroNN.gaia import mag_to_fakemag\n",
    "\n",
    "with h5py.File('gaia_edr3_dr17_syncspec_train.h5') as F:  # ensure the file will be cleaned up\n",
    "    parallax = np.array(F['parallax_w_zp'])\n",
    "    parallax_error = np.array(F['parallax_err'])\n",
    "    fakemag = np.array(F['fakemag_w_zp'])\n",
    "    fakemag_err = np.array(F['fakemag_w_zp_err'])\n",
    "    spectra = np.array(F['spectra'])\n",
    "    Kcorr = np.array(F['corrected_K'])  # extinction corrected Ks\n",
    "\n",
    "spectra[np.abs(spectra)>2] = 1.\n",
    "idx = (fakemag>0)\n",
    "\n",
    "#training\n",
    "bcnn_net = ApogeeBCNN()\n",
    "bcnn_net.max_epochs = 35\n",
    "bcnn_net.callbacks = ErrorOnNaN()\n",
    "bcnn_net.input_norm_mode = 3  # center label but not scale pixel\n",
    "bcnn_net.labels_norm_mode = 4  # scale label but not center it\n",
    "bcnn_net._last_layer_activation = \"softplus\"\n",
    "bcnn_net.targetname = ['Ks-band fakemag']\n",
    "bcnn_net.num_hidden = [192, 64]\n",
    "bcnn_net.batch_size = 256\n",
    "bcnn_net.metrics = [mean_absolute_error, mean_error, mean_absolute_percentage_error]\n",
    "bcnn_net.fit(spectra[idx], np.expand_dims(fakemag[idx], axis=1), labels_err=np.expand_dims(fakemag_err[idx], axis=1),)\n",
    "bcnn_net.save(\"astroNN_gaia_dr17_modell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baab7fa-db08-4fca-ba74-727d336d2606",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72078479-5488-465e-85ba-67cbefe9c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, vstack\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroNN.apogee import allstar\n",
    "from tqdm.notebook import tqdm\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "from astroNN.datasets import xmatch\n",
    "from astroNN.models import ApogeeBCNN\n",
    "from astroNN.nn.losses import mean_absolute_error, mean_error, mean_absolute_percentage_error\n",
    "\n",
    "allstar_f = fits.getdata(allstar(dr=17))\n",
    "ra = allstar_f[\"ra\"]\n",
    "dec = allstar_f[\"dec\"]\n",
    "\n",
    "ra[0] = 0\n",
    "dec[0] = 0\n",
    "\n",
    "# load catalogs\n",
    "apokasc3 = fits.getdata(\"APOKASC_cat_v6.6.1.fits.zip\")\n",
    "good_ages = ((apokasc3[\"APOKASC2_AGE\"] != -9999.) & (apokasc3[\"APOKASC2_AGE_MERR\"]/apokasc3[\"APOKASC2_AGE\"] < 0.5))\n",
    "apokasc3 = apokasc3[good_ages]\n",
    "\n",
    "f_age_low_M = fits.getdata(\"kepler_low_metallicity_with_samples.fits\")  # ask Ted Mackereth for the file somewhere\n",
    "\n",
    "idx_1, idx_2, sep = xmatch(apokasc3[\"RA\"], apokasc3[\"DEC\"], ra, dec)\n",
    "idx_3, idx_4, sep = xmatch(f_age_low_M[\"RA\"], f_age_low_M[\"DEC\"], ra, dec)\n",
    "\n",
    "\n",
    "idx_combined, unique_indices = np.unique(np.concatenate([idx_4, idx_2]), return_index=True)\n",
    "contspec = fits.getdata(\"contspec_dr17_synspec.fits\")\n",
    "input_spec = contspec[idx_combined]\n",
    "input_spec[np.abs(input_spec)>2] = 1.\n",
    "\n",
    "all_age = np.concatenate([f_age_low_M[\"Age_med \"]/1e9, apokasc3['APOKASC2_AGE']])[unique_indices]\n",
    "all_age_err = np.concatenate([f_age_low_M[\"Age_Sd \"]/1e9, apokasc3['APOKASC2_AGE_MERR']])[unique_indices]\n",
    "all_mass = np.concatenate([f_age_low_M[\"Mass_med \"], apokasc3['APOKASC2_MASS']])[unique_indices]\n",
    "all_mass_err = np.concatenate([f_age_low_M[\"Mass_Sd \"], apokasc3['APOKASC2_MASS_RANERR']])[unique_indices]\n",
    "\n",
    "agemass = np.stack([all_age, all_mass]).T\n",
    "agemass_err = np.stack([all_age_err, all_mass_err]).T\n",
    "\n",
    "bcnn_net = ApogeeBCNN()\n",
    "bcnn_net.max_epochs = 60\n",
    "bcnn_net.input_norm_mode = 3  # center label but not scale pixel\n",
    "bcnn_net.labels_norm_mode = 4  # scale label but not center it\n",
    "bcnn_net._last_layer_activation = \"softplus\"\n",
    "bcnn_net.targetname = ['age', 'mass']\n",
    "bcnn_net.num_hidden = [128,64]\n",
    "bcnn_net.batch_size = 32\n",
    "bcnn_net.reduce_lr_patience = 4\n",
    "bcnn_net.metrics = [mean_absolute_error, mean_error, mean_absolute_percentage_error]\n",
    "bcnn_net.fit(input_spec, agemass, labels_err=agemass_err)\n",
    "bcnn_net.save(\"APOKASC2_BCNN_age_combined_dr17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
